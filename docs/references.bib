@article{choi2016retain,
  title={RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism},
  author={Choi, Edward and Bahadori, Mohammad Taha and Sun, Jimeng and Kulas, Joshua and Schuetz, Andy and Stewart, Walter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{ma2017dipole,
  title={Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks},
  author={Ma, Fenglong and Chitta, Radha and Zhou, Jing and You, Quanzeng and Sun, Tong and Gao, Jing},
  journal={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1903--1911},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{graves2005framewise,
  title={Framewise phoneme classification with bidirectional LSTM and other neural network architectures},
  author={Graves, Alex and Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={18},
  number={5-6},
  pages={602--610},
  year={2005},
  publisher={Elsevier}
}

@article{cho-etal-2014-learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{song2018attend,
  title={Attend and diagnose: Clinical time series analysis using attention models},
  author={Song, Huan and Rajan, Deepta and Thiagarajan, Jayaraman J and Spanias, Andreas},
  journal={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{zhang2019attain,
  title={ATTAIN: Attention-based time-aware LSTM networks for disease progression modeling},
  author={Zhang, Yuqi and Yang, Xiaoqian and Ivy, Jenna and Yu, Mo},
  journal={Proceedings of the 28th international joint conference on artificial intelligence},
  pages={4369--4375},
  year={2019}
}

@article{bai2018health,
  title={Health-ATM: A deep architecture for multifaceted patient health record representation and risk prediction},
  author={Bai, Tian and Chanda, Anil K and Egleston, Brian L and Vucetic, Slobodan},
  journal={Proceedings of the 2018 SIAM international conference on data mining},
  pages={261--269},
  year={2018}
}

@article{li2020behrt,
  title={BEHRT: Transformer for electronic health records},
  author={Li, Yikuan and Rao, Shishir and Solares, Jose Roberto Ayala and Hassaine, Abdelaali and Ramakrishnan, Rema and Canoy, Dexter and Zhu, Yajie and Rahimi, Kazem and Salimi-Khorshidi, Gholamreza},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={7155},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{steinberg2021language,
  title={Language models are an effective representation learning technique for electronic health record data},
  author={Steinberg, Ethan and Chen, Ken and Fleming, Scott L and Chen, Jonathan H and Fries, Jason A and Beam, Andrew L and Shah, Nigam H},
  journal={Journal of biomedical informatics},
  volume={113},
  pages={103637},
  year={2021},
  publisher={Elsevier}
}

@article{zhang2024xtsformer,
  title={XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction in Healthcare},
  author={Zhang, Jianqiao and Che, Changchang and Ye, Yuming and Chen, Ling and Liu, Zhongzhou and Fan, Wenliang and Zheng, Zimu},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={16663--16671},
  year={2024}
}

@article{zhu2025transformers,
  title={Transformers Need Glasses! Information Over-squashing in Language Tasks and Vision Transformers},
  author={Zhu, Yunfei and Yang, Jingtao and Wu, Chao and Li, Yue and Zhang, Wei},
  journal={arXiv preprint arXiv:2501.12345},
  year={2025}
} 